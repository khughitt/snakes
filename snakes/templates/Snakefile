################################################################################
#                  _             
#  ___ _ __   __ _| | _____  ___ 
# / __| '_ \ / _` | |/ / _ \/ __|
# \__ \ | | | (_| |   <  __/\__ \
# |___/_| |_|\__,_|_|\_\___||___/
#                               
# Data integration and machine learning pipeline built on Snakemake
#
# https://github.com/khughitt/snakes
#
{% set title_underline = '-' * (config['name'] | length + config['version'] | length + 1) -%}
#  {{ config['name'] }} {{ config['version'] }}
#  {{ title_underline }}
#
#  Config : {{ config['config_file'] }}
#  Date   : {{ date_str }}
#
#  Data sources:
{% for dataset_name, dataset_params in datasets.items() -%}
#    - {{ dataset_name }}: {{ dataset_params['path'] }}
{% endfor -%}
#
{% set output_dir = '/'.join([config['output_dir'], config['name'] | replace(' ', '_'), config['version']]) -%}
#  Output dir: {{ output_dir }} 
#    
################################################################################
import glob
import os
import yaml
import numpy as np
import pandas as pd
from snakes import aggregation, filters

# load sample and response metadata
sample_metadata   = pd.read_csv('{{ config["metadata"]["samples"] }}', index_col=0)
response_metadata = pd.read_csv('{{ config["metadata"]["response"] }}', index_col=0)

# create output directory, if needed
output_dir = '{{ output_dir }}' 

if not os.path.exists(output_dir):
    os.makedirs(output_dir, mode=0o755)

{############################################################################################-#}
{#                                                                                           -#}
{# Global variables                                                                          -#}
{#                                                                                           -#}
{############################################################################################-#}
{# list used to keep track of different feature sources to use for training set construction -#}
{% set training_set_features = [] -%}

{# list used to keep track of simple rules that should not be run on a cluster               -#}
{% set local_rules = [] -%}

{############################################################################################-#}
{#                                                                                           -#}
{# Default target
{#                                                                                           -#}
{############################################################################################-#}
rule all:
    input: "{{ output_dir }}/training_set.csv"

{############################################################################################-#}
{#                                                                                           -#}
{# Load features                                                                             -#}
{#                                                                                           -#}
{############################################################################################-#}
{% for dataset_name, dataset_params in datasets.items() -%}
{% include 'data/' + dataset_params['name'] + '.snakefile' -%}
{% endfor -%}

{############################################################################################-#}
{#                                                                                           -#}
{# Cluster aggregation                                                                       -#}
{#                                                                                           -#}
{############################################################################################-#}
{% for dataset_name, dataset_params in datasets.items() -%}
{% if dataset_params['role'] == 'feature' and 'clustering' in  dataset_params -%}
{% for clust_method, clust_params in dataset_params['clustering'].items() -%}
{% set cur_input = "%s/features/%s.csv" | format(output_dir, dataset_name) -%}
{% include 'aggregation/clustering_' + clust_method + '.snakefile' %}
{% endfor -%}
{% endif -%}
{% endfor -%}

{############################################################################################-#}
{#                                                                                           -#}
{# Gene set aggregation                                                                      -#}
{#                                                                                           -#}
{############################################################################################-#}
{% set preproccesed_gmt_files = [] -%}
{% for dataset_name, dataset_params in datasets.items() -%}
    {% if dataset_params['role'] == 'feature' and 'gene_sets' in  dataset_params -%}
        {% for gene_set, gene_set_params in config['gene_sets'].items() -%}
            {% for gmt in gene_set_params['gmts'] -%}
                {% set gmt_name = gmt | basename_no_ext -%}
                {% set preprocessed_gmt = "%s/gene_sets/%s-%s.gmt" | format(output_dir, gmt_name, dataset_params['xid']) -%}
                {% if preprocessed_gmt not in preproccesed_gmt_files -%}
{% include 'annotations/load_gmt.snakefile' -%}
                    {% do preproccesed_gmt_files.append(preprocessed_gmt) -%}
                {% endif -%}
                {% set cur_input = "%s/features/%s.csv" | format(output_dir, dataset_name) -%}
{% include 'aggregation/gene_set_' + gene_set + '.snakefile' %}
            {% endfor -%}
        {% endfor -%}
    {% endif -%}
{% endfor %}

################################################################################
#
# Combine features
#
################################################################################
rule combine_features:
    input: expand("{{ output_dir }}/features/{features}", features={{ training_set_features }})
    output: "{{ output_dir }}/training_set.csv"
    run:
        # combine features into a unified <sample> x <feature> dataframe
        func = lambda x: pd.read_csv(x, index_col=0).T
        pd.concat(map(func, input), axis=1).to_csv(output[0], index_label='sample_id')

################################################################################
#
# Other settings
#
################################################################################
{% set localrules_str = ', '.join(local_rules) -%}
localrules: {{ localrules_str }}


