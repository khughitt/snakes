---
date: "`r format(Sys.time(), '%d %B, %Y')`"
params:
  rmd: ""
  title: "EDA: General (Numeric Matrix)"
  digits: 2
title: "`r params$title`"
output:
  html_document:
    theme: journal
    highlight: textmate
    df_print: kable
    toc: true
    toc_depth: 2
    code_folding: hide
---

```{r setup, include = FALSE}
library(knitr)
opts_chunk$set(echo = FALSE, message = FALSE, dpi = 120)
set.seed(snakemake@params$random_seed)

knitr::opts_knit$set(progress = TRUE, verbose = TRUE)
```

```{r load_libraries, include = FALSE}
library(arrow)
library(ggpmisc)
library(ggrepel)
library(janitor)
library(NMF)
library(RColorBrewer)
library(rrcov)
library(tidyverse)
library(uwot)
library(viridis)
```

```{r helper_function}
# helper function to round numbers, including trailing zeros
round_ <- function(x) {
  formatC(round(x, params$digits), params$digits, format = "f")
}

# helper function to load data from a of unknown type
load_data <- function(x) {
  if (endsWith(x, ".csv")) {
    dat <- read_csv(x, col_types = cols())
  } else if (endsWith(x, ".tsv")) {
    dat <- read_tsv(x, col_types = cols())
  } else if (endsWith(x, ".feather")) {
    dat <- arrow::read_feather(x)
  }

  dat <- dat %>%
    column_to_rownames(colnames(dat)[1])

  # drop columns with only a single level
  mask <- apply(dat, 2, function(x) {
    length(unique(x)) > 1
  })

  dat <- dat[, mask]

  # attempt to detect categorical/binary variables and convert them to factors;
  # for columns only containing numbers, convert to numeric
  for (cname in colnames(dat)) {
    n_levels <- length(unique(dat[, cname]))

    if (n_levels < nrow(dat) && n_levels <= 25) {
      # categorical
      dat[, cname] <- factor(dat[, cname])
    } else if (all(grepl("^[0-9]+\\.?[0-9]*", dat[, cname]))) {
      # numeric
      dat[, cname] <- as.numeric(dat[, cname])
    } else if (n_levels == nrow(dat)) {
      # likely identifiers (non-numeric, all unique)
      dat <- dat[, colnames(dat) != cname]
    }
  }

  dat
}

# helper function to get a list of colormaps to use for a set of annotations
get_color_map <- function(annot) {
  cmap <- list()

  for (x in colnames(annot)) {
    # determine number of unique annotation values
    num_levels <- length(unique(pull(annot, x)))

    # for annotations with 8 or fewer levels, use Set2
    if (num_levels <= 8) {
      cmap[[x]] <- brewer.pal(8, 'Set2')
    } else {
      cmap[[x]] <- viridis(num_levels)
    }
  }
  cmap
}
```


```{r debug_save1}
# TESTING
save.image("~/tmp-rmd.rda")
```

```{r load_data}
# load dataset and convert to a matrix
dat <- read_feather(snakemake@input[[1]])

dat <- dat %>%
  column_to_rownames(colnames(dat)[1]) %>%
  as.matrix()
```

```{r load_metadata}
# load metadata
col_mdata <- NULL
row_mdata <- NULL

if (snakemake@params$metadata$columns != '') {
  col_mdata <- load_data(snakemake@params$metadata$columns)
}

if (snakemake@params$metadata$rows != '') {
  row_mdata <- load_data(snakemake@params$metadata$rows)
}
```


```{r load_styles}
col_annot <- NULL
col_color <- NULL
row_annot <- NULL
row_color <- NULL

# load column styles
if (!is.null(col_mdata) && all(colnames(dat) %in% rownames(col_mdata))) {
  col_styles <- snakemake@params$styles$columns

  # drop any columns excluded during load
  valid_column_styles <- as.character(unlist(col_styles))
  valid_column_styles <- valid_column_styles[valid_column_styles %in% colnames(col_mdata)]

  # match data / metadata order
  col_mdata <- col_mdata[match(rownames(col_mdata), colnames(dat)), ]

  # column annotations to display in tables
  col_annot <- col_mdata %>%
    select(valid_column_styles) %>%
    rownames_to_column('column_id')

  # column fill color
  if (length(col_styles$color) > 0) {
    col_color <- col_styles$color[col_styles$color %in% valid_column_styles]
  }
}

# load row styles
if (!is.null(row_mdata) && all(colnames(dat) %in% rownames(row_mdata))) {
  row_styles <- snakemake@params$styles$rows

  # drop any columns excluded during load
  valid_row_styles <- as.character(unlist(row_styles))
  valid_row_styles <- valid_row_styles[valid_row_styles %in% colnames(row_mdata)]

  # match data / metadata order
  row_mdata <- row_mdata[match(rownames(row_mdata), rownames(dat)), ]

  # column annotations to display in tables
  row_annot <- row_mdata %>%
    select(valid_row_styles) %>%
    rownames_to_column('row_id')

  # row fill color
  if (length(row_styles$color) > 0) {
    row_color <- row_styles$color[row_styles$color %in% valid_row_styles]
  }
}
```

```{r dev_mode_check, include = snakemake@params$dev_mode, eval = snakemake@params$dev_mode, results = 'asis'}
cat("<span style='color: red; font-weight: bold'>= DEVELOPMENT MODE =</span>\n\n")
```

```{r variance_check}
# remove any zero variance rows/columns since these are generally not that
# informative and can cause problems with many methods
row_vars <- apply(dat, 1, var, na.rm = TRUE)
col_vars <- apply(dat, 2, var, na.rm = TRUE)

if (sum(row_vars == 0) > 0) {
  mask <- row_vars > 0
  dat <- dat[mask, ]

  print(sprintf("Excluding %d/%d rows with zero variance...", sum(!mask), length(mask)))
}

if (sum(col_vars == 0) > 0) {
  mask <- col_vars > 0
  dat <- dat[, mask]

  print(sprintf("Excluding %d/%d columns with zero variance...", sum(!mask), length(mask)))
}

# generate a logged version of data
# in cases where negative values are preset, these will be transformed as if they were
# positive, while still preserving the sign of the values
dat_log2 <- dat

neg_mask <- dat_log2 < 0

dat_log2[!neg_mask] <- log2(dat_log2[!neg_mask] + 1)
dat_log2[neg_mask] <- -log2(abs(dat_log2[neg_mask]) + 1)
```

```{r debug_save2}
# TESTING
save.image("~/tmp-rmd.rda")
```

Overview
--------

```{r heatmap_raw, fig.width = 1920/120, fig.height = 1400/120}
# create an alternate version of the dataset with missing values removed

# first, determine whether missing values are clustered among rows or columns, if
# either..
row_missing <- apply(dat, 1, function(x) {
  sum(is.na(x))
})

col_missing <- apply(dat, 2, function(x) {
  sum(is.na(x))
})

# as a heuristic, we will compare the percent of rows/columns with > 10% missing values
# row10 <- sum(row_missing > (0.1 * nrow(dat)))
# col10 <- sum(col_missing > (0.1 * ncol(dat)))

# TODO: convert to a function that iteratively removes rows/columns based on which ones
# have the most missing values?

# approach: compute _ratios_ of missing values for each col/row, remove one with
# highest ratio, then repeat...

# for now, to keep things simple, we will just remove cols, then rows..
col_mask <- col_missing <= 0.1 * ncol(dat)

dat_complete <- dat[, col_mask]
dat_complete <- dat_complete[complete.cases(dat_complete), ]

dat_complete_log2 <- dat_log2[, col_mask]
dat_complete_log2 <- dat_complete_log2[complete.cases(dat_complete_log2), ]

# plot at most 1000 rows/columns
row_ind_complete <- sample(nrow(dat_complete), min(nrow(dat_complete), 1000))
col_ind_complete <- sample(ncol(dat_complete), min(ncol(dat_complete), 1000))

dat_subset <- as.matrix(dat_complete[row_ind_complete, col_ind_complete])
dat_subset_log2 <- as.matrix(dat_complete_log2[row_ind_complete, col_ind_complete])

# exclude any entries with zero variance; these will cause problems during
# several of the eda steps
# mask <- apply(dat_subset, 1, var) > 0

# if (sum(!mask) > 0) {
#   print(sprintf("Excluding %d/%d entries with zero variance.", !mask, length(mask)))
#   dat_subset <- dat_subset[mask, ]
# }

#
# heatmap (raw)
#
heatmap_args <- list(
  x = dat_subset,
  color = viridis(100),
  main = "Data Heatmap (Raw / Euclidean Distance)",
  annColors = list()
)

# add column and row annotations, if specified
if (!is.null(col_color)) {
  heatmap_args[["annCol"]] <- col_mdata[col_ind_complete, ] %>%
    select(all_of(col_color)) %>%
    as.data.frame()

  heatmap_args[["annColors"]] <- get_color_map(heatmap_args[["annCol"]])
}
if (!is.null(row_color)) {
  heatmap_args[["annRow"]] <- row_mdata[row_ind_complete, ] %>%
    select(all_of(row_color)) %>%
    as.data.frame()

  heatmap_args[["annColors"]] <- c(heatmap_args[["annColors"]],
                                   get_color_map(heatmap_args[["annRow"]]))
}
do.call(aheatmap, heatmap_args)

#
# heatmap (raw, pearson)
#
heatmap_args$distfun <- 'pearson'
heatmap_args$main <- 'Data Heatmap (Raw / Pearson Correlation)'
do.call(aheatmap, heatmap_args)

#
# heatmap (raw, spearman)
#
heatmap_args$distfun <- 'spearman'
heatmap_args$main <- 'Data Heatmap (Raw / Spearman Correlation)'
do.call(aheatmap, heatmap_args)
```

```{r heatmap_log2, fig.width = 1920/120, fig.height = 1400/120}
#
# heatmap (log2)
#
heatmap_args$x <- dat_subset_log2
heatmap_args$distfun <- 'euclidean'
heatmap_args$main <- 'Data Heatmap (Log2 / Euclidean Distance)'

do.call(aheatmap, heatmap_args)

#
# heatmap (log2, pearson)
#
heatmap_args$distfun <- 'pearson'
heatmap_args$main <- 'Data Heatmap (Log2 / Pearson Correlation)'

do.call(aheatmap, heatmap_args)

#
# heatmap (log2, spearman)
#
heatmap_args$distfun <- 'spearman'
heatmap_args$main <- 'Data Heatmap (Log2 / Spearman Correlation)'

do.call(aheatmap, heatmap_args)
```

**Dimensions**:

- \# rows: `r nrow(dat)`
- \# cols: `r ncol(dat)`

**Column types**:

```{r column_types}
col_type <- apply(dat, 2, class)
tabyl(col_type)
```

Values
------

```{r density, warning = FALSE}
qplot(as.numeric(as.matrix(dat)), geom = 'density', fill = I('blue'), alpha = 0.75) +
  xlab("Value") +
  ggtitle(sprintf("Distribution of data values (%s)", snakemake@params$name)) +
  theme_bw() +
  theme(legend.position = 'none')
```

```{r density_log2, warning = FALSE}
qplot(as.numeric(as.matrix(dat_log2)), geom = 'density', fill = I('blue'), alpha = 0.75) +
  xlab("Value (Log2)") +
  ggtitle(sprintf("Distribution of data log-values (%s)", snakemake@params$name)) +
  theme_bw() +
  theme(legend.position = 'none')
```

- min: `r round_(min(dat, na.rm = TRUE))`
- mean: `r round_(median(dat, na.rm = TRUE))`
- median: `r round_(median(dat, na.rm = TRUE))`
- max: `r round_(max(dat, na.rm = TRUE))`
- quartiles: `r round_(quantile(dat, na.rm = TRUE))`

```{r include = FALSE}
na_mask <- is.na(dat)
num_total <- length(na_mask)

# number zeros
zero_mask <- dat == 0
num_zero <- sum(zero_mask, na.rm = TRUE)
pct_zero <- 100 * num_zero / num_total

# number positive
pos_mask <- dat > 0
num_pos <- sum(pos_mask, na.rm = TRUE)
pct_pos <- 100 * num_pos / num_total

# number negative
neg_mask <- dat < 0
num_neg <- sum(neg_mask, na.rm = TRUE)
pct_neg <- 100 * num_neg / num_total
```

- \# zeros: `r sprintf("%d / %d (%0.2f)%%", num_zero, num_total, pct_zero)`
- \# positive values: `r sprintf("%d / %d (%0.2f)%%", num_pos, num_total, pct_pos)`
- \# negative values: `r sprintf("%d / %d (%0.2f)%%", num_neg, num_total, pct_neg)`

Missing Values
==============

**Overall**

```{r debug_save3}
# TESTING
save.image("~/tmp-rmd.rda")
```

```{r missing_values, include = FALSE}
# num missing
num_missing <- sum(na_mask)
pct_missing <- 100 * num_missing / num_total
```

```{r heatmap_missing_values, fig.width = 1920/120, fig.height = 1400/120}
# select row and column indices to for sub-sampling (including missing values)
row_ind <- sample(nrow(dat), min(nrow(dat), 1000))
col_ind <- sample(ncol(dat), min(ncol(dat), 1000))

# create an alternate version of indices that exclude rows/columns with zero variance
# row_mask <- apply(dat[row_ind, ], 1, var) > 0
# col_mask <- apply(dat[col_ind, ], 2, var) > 0

# row_ind_safe <- row_ind[row_mask]
# col_ind_safe <- col_ind[col_mask]

# determine column and row annotations for heatmaps based on the same subsampled data
if (!is.null(col_color)) {
  heatmap_args[["annCol"]] <- col_mdata[col_ind, ] %>%
    select(col_color) %>%
    as.data.frame()
}
if (!is.null(row_color)) {
  heatmap_args[["annRow"]] <- row_mdata[row_ind, ] %>%
    select(row_color) %>%
    as.data.frame()
}

if (num_missing > 0) {
  dat_missing <- is.na(dat) * 1

  heatmap_args$x <- dat_missing[row_ind, col_ind]
  heatmap_args$distfun <- 'euclidean'
  heatmap_args$main <- "Missing values"

  do.call(aheatmap, heatmap_args)
}
```

- \# missing values: `r sprintf("%d / %d (%0.2f)%%", num_missing, num_total, pct_missing)`

```{r echo = FALSE, include = num_missing > 0, eval = num_missing > 0, results = 'asis'}
cat("\n**Missing values by row**:\n")
```

```{r density_plot_missing_vals_by_row, include = num_missing > 0, eval = num_missing > 0}
qplot(row_missing, geom = 'density', fill = I('purple'), alpha = 0.75) +
  xlab("# NA") +
  ggtitle(sprintf("Distribution of row missing values (%s)", snakemake@params$name)) +
  theme_bw() +
  theme(legend.position = 'none')
```

```{r table_missing_vals_by_row, results = 'asis', include = num_missing > 0, eval = num_missing > 0}
tbl_out <- data.frame(row_id = rownames(dat), num_missing = as.numeric(row_missing)) %>%
  arrange(desc(num_missing)) %>%
  head(10)

if (!is.null(row_annot)) {
  tbl_out <- tbl_out %>%
    inner_join(row_annot, by = 'row_id')
}

tbl_out
```

```{r echo = FALSE, include = num_missing > 0, eval = num_missing > 0, results = 'asis'}
cat("\n**Missing values by column**:\n")
```

```{r density_plot_missing_vals_by_col, include = num_missing > 0, eval = num_missing > 0}
qplot(col_missing, geom = 'density', fill = I('green'), alpha = 0.75) +
  xlab("# NA") +
  ggtitle(sprintf("Distribution of column missing values (%s)", snakemake@params$name)) +
  theme_bw() +
  theme(legend.position = 'none')
```

```{r table_missing_vals_by_col, results = 'asis', include = num_missing > 0, eval = num_missing > 0}
tbl_out <- data.frame(column_id = colnames(dat), num_missing = as.numeric(col_missing)) %>%
  arrange(desc(num_missing)) %>%
  head(10)

if (!is.null(col_annot)) {
  tbl_out <- tbl_out %>%
    inner_join(col_annot, by = 'column_id')
}

tbl_out
```

Row Statistics
--------------

**Row Means**

```{r row_means}
row_means <- apply(dat, 1, mean, na.rm = TRUE)

qplot(row_means, geom = 'density', fill = I('green'), alpha = 0.75) +
  xlab("Row mean") +
  ggtitle(sprintf("Distribution of row means (%s)", snakemake@params$name)) +
  theme_bw() +
  theme(legend.position = 'none')
```

- Row mean (min): `r round_(min(row_means))`
- Row mean (median): `r round_(median(row_means))`
- Row mean (mean): `r round_(mean(row_means))`
- Row mean (max): `r round_(max(row_means))`

Largest row means:

```{r row_means_table_largest}
row_means_dat <- data.frame(row = names(row_means), mean = row_means) %>%
  as_tibble() %>%
  arrange(desc(mean))

row_means_dat %>%
  head(10)
```

Smallest row means:

```{r row_means_table_smallest}
row_means_dat %>%
  arrange(mean) %>%
  head(10)
```

**Row Medians**

```{r row_medians}
row_medians <- apply(dat, 1, median, na.rm = TRUE)

qplot(row_medians, geom = 'density', fill = I('green'), alpha = 0.75) +
  xlab("Row median") +
  ggtitle(sprintf("Distribution of row medians (%s)", snakemake@params$name)) +
  theme_bw() +
  theme(legend.position = 'none')
```

- Row median (min): `r round_(min(row_medians))`
- Row median (median): `r round_(median(row_medians))`
- Row median (mean): `r round_(mean(row_medians))`
- Row median (max): `r round_(max(row_medians))`

Largest row medians:

```{r row_medians_table_largest}
row_medians_dat <- data.frame(row = names(row_medians), median = row_medians) %>%
  as_tibble() %>%
  arrange(desc(median))

row_medians_dat %>%
  head(10)
```

Smallest row medians:

```{r row_medians_table_smallest}
row_medians_dat %>%
  arrange(median) %>%
  head(10)
```

**Row Maximums**

```{r row_maxes}
row_maxes <- apply(dat, 1, max, na.rm = TRUE)

qplot(row_maxes, geom = 'density', fill = I('green'), alpha = 0.75) +
  xlab("Row maximum") +
  ggtitle(sprintf("Distribution of row maximums (%s)", snakemake@params$name)) +
  theme_bw() +
  theme(legend.position = 'none')
```

- Row maximum (min): `r round_(min(row_maxes))`
- Row maximum (median): `r round_(median(row_maxes))`
- Row maximum (mean): `r round_(mean(row_maxes))`
- Row maximum (max): `r round_(max(row_maxes))`

Largest row maximums:

```{r row_maxes_table_largest}
row_maxes_dat <- data.frame(row = names(row_maxes), max = row_maxes) %>%
  as_tibble() %>%
  arrange(desc(max))

row_maxes_dat %>%
  head(10)
```

Smallest row maximums:

```{r row_maxes_table_smallest}
row_maxes_dat %>%
  arrange(max) %>%
  head(10)
```

**Row Standard Deviations**

```{r row_stdevs}
row_sds <- apply(dat, 1, sd, na.rm = TRUE)

qplot(row_sds, geom = 'density', fill = I('green'), alpha = 0.75) +
  xlab("Row standard deviation") +
  ggtitle(sprintf("Distribution of row standard deviations (%s)", snakemake@params$name)) +
  theme_bw() +
  theme(legend.position = 'none')
```

- Row stdev (min): `r round_(min(row_sds))`
- Row stdev (median): `r round_(median(row_sds))`
- Row stdev (mean): `r round_(mean(row_sds))`
- Row stdev (max): `r round_(max(row_sds))`

Largest row standard deviations:

```{r row_sds_table_largest}
row_sds_dat <- data.frame(row = names(row_sds), sd = row_sds) %>%
  as_tibble() %>%
  arrange(desc(sd))

row_sds_dat %>%
  head(10)
```

Smallest row standard deviations:

```{r row_sds_table_smallest}
row_sds_dat %>%
  arrange(sd) %>%
  head(10)
```

Column Statistics
-----------------

**Column Means**

```{r column_means}
col_means <- apply(dat, 2, mean, na.rm = TRUE)

qplot(col_means, geom = 'density', fill = I('purple'), alpha = 0.75) +
  xlab("Column mean") +
  ggtitle("Distribution of column means") +
  theme_bw() +
  theme(legend.position = 'none')
```

- Column mean (min): `r round_(min(col_means))`
- Column mean (median): `r round_(median(col_means))`
- Column mean (mean): `r round_(mean(col_means))`
- Column mean (max): `r round_(max(col_means))`

Largest column means:

```{r col_means_table_largest}
col_means_dat <- data.frame(col = names(col_means), mean = col_means) %>%
  as_tibble() %>%
  arrange(desc(mean))

col_means_dat %>%
  head(10)
```

Smallest column means:

```{r col_means_table_smallest}
col_means_dat %>%
  arrange(mean) %>%
  head(10)
```

**Column Medians**

```{r column_medians}
col_medians <- apply(dat, 2, median, na.rm = TRUE)

qplot(col_medians, geom = 'density', fill = I('purple'), alpha = 0.75) +
  xlab("Column median") +
  ggtitle("Distribution of column medians") +
  theme_bw() +
  theme(legend.position = 'none')
```

- Column median (min): `r round_(min(col_medians))`
- Column median (median): `r round_(median(col_medians))`
- Column median (mean): `r round_(mean(col_medians))`
- Column median (max): `r round_(max(col_medians))`

Largest column medians:

```{r col_medians_table_largest}
col_medians_dat <- data.frame(col = names(col_medians), median = col_medians) %>%
  as_tibble() %>%
  arrange(desc(median))

col_medians_dat %>%
  head(10)
```

Smallest column medians:

```{r col_medians_table_smallest}
col_medians_dat %>%
  arrange(median) %>%
  head(10)
```

**Column Maximums**

```{r column_maxes}
col_maxes <- apply(dat, 2, max, na.rm = TRUE)

qplot(col_maxes, geom = 'density', fill = I('purple'), alpha = 0.75) +
  xlab("Column Maximum") +
  ggtitle("Distribution of column Maximums") +
  theme_bw() +
  theme(legend.position = 'none')
```

- Column Maximum (min): `r round_(min(col_maxes))`
- Column Maximum (median): `r round_(median(col_maxes))`
- Column Maximum (mean): `r round_(mean(col_maxes))`
- Column Maximum (max): `r round_(max(col_maxes))`

Largest column maximums:

```{r col_maxes_table_largest}
col_maxes_dat <- data.frame(col = names(col_maxes), median = col_maxes) %>%
  as_tibble() %>%
  arrange(desc(median))

col_maxes_dat %>%
  head(10)
```

Smallest column maximums:

```{r col_maxes_table_smallest}
col_maxes_dat %>%
  arrange(median) %>%
  head(10)
```

**Column Standard Deviations**

```{r column_stdevs}
col_sds <- apply(dat, 2, sd, na.rm = TRUE)

qplot(col_sds, geom = 'density', fill = I('purple'), alpha = 0.75) +
  xlab("Column standard deviation") +
  ggtitle("Distribution of column standard deviations") +
  theme_bw() +
  theme(legend.position = 'none')
```

- Column stdev (min): `r round_(min(col_sds))`
- Column stdev (median): `r round_(median(col_sds))`
- Column stdev (mean): `r round_(mean(col_sds))`
- Column stdev (max): `r round_(max(col_sds))`

Largest column standard deviations:

```{r col_sds_table_largest}
col_sds_dat <- data.frame(col = names(col_sds), median = col_sds) %>%
  as_tibble() %>%
  arrange(desc(median))

col_sds_dat %>%
  head(10)
```

Smallest column standard deviations:

```{r col_sds_table_smallest}
col_sds_dat %>%
  arrange(median) %>%
  head(10)
```

Correlations
------------

### Row correlations

```{r row_median_pairwise_correlations}
# compute row pairwise correlation matrix
#row_cor_mat <- cor(t(dat), use = 'pairwise.complete')
row_cor_mat <- coop::pcor(t(dat), use = 'pairwise.complete')
median_row_cors <- apply(row_cor_mat, 1, median, na.rm = TRUE)
```

```{r average_row_median_pairwise_correlation, result = 'asis'}
cat(sprintf("\n- **Average row median pairwise correlation (Mean): %0.2f**:\n", mean(median_row_cors)))
cat(sprintf("\n- **Average row median pairwise correlation (Median): %0.2f**:\n", median(median_row_cors)))
```

```{r density_plot_row_correlations}
qplot(median_row_cors, geom = 'density', fill = I('green'), alpha = 0.75) +
  xlab("Median pairwise pearson correlation") +
  ggtitle("Distribution of median pairwise correlations (rows)") +
  theme_bw() +
  theme(legend.position = 'none')
```

```{r debug_save4}
# TESTING
save.image("~/tmp-rmd.rda")
```

```{r heatmap_row_correlations, fig.width = 1920/120, fig.height = 1400/120}
# heatmap_dat <- row_cor_mat[row_ind_safe, row_ind_safe]
heatmap_dat <- row_cor_mat[row_ind, row_ind]

# drop na's resulting from zero variance rows
# mask <- apply(heatmap_dat, 1, function(x) { sum(is.na(x)) }) != nrow(heatmap_dat)
# heatmap_dat <- heatmap_dat[mask, mask]

heatmap_args$x <- heatmap_dat
heatmap_args$main <- sprintf("Row correlation matrix (n = %d)", nrow(row_cor_mat))
heatmap_args$annCol <- NULL

do.call(aheatmap, heatmap_args)
```

**High positive correlation rows**:

Rows with the highest positive pairwise correlations with all other rows.

```{r high_pos_cor_rows}
row_cor_dat <- data.frame(row_id = rownames(dat), cor = as.numeric(median_row_cors))

tbl_out <- row_cor_dat %>%
    arrange(desc(cor)) %>%
    head(10)

if (!is.null(row_annot)) {
  tbl_out <- tbl_out %>%
    inner_join(row_annot, by = 'row_id')
}

tbl_out
```

```{r high_neg_cor_rows_header, include = min(median_row_cors) < 0, eval = min(median_row_cors) < 0, results = 'asis'}
cat('\n**High negative correlation rows**:\n')
cat('\n*Rows with the strongest inverse pairwise correlations with all other rows.\n')
```

```{r high_neg_cor_rows, include = min(median_row_cors) < 0, eval = min(median_row_cors) < 0}
tbl_out <- row_cor_dat %>%
    arrange(cor) %>%
    head(10)

if (!is.null(row_annot)) {
  tbl_out <- tbl_out %>%
    inner_join(row_annot, by = 'row_id')
}

tbl_out
```

**Low correlation rows**

Rows with the lowest median pairwise correlation with all other rows.

```{r low_cor_rows}
tbl_out <- row_cor_dat %>%
    arrange(abs(cor)) %>%
    head(10)

if (!is.null(row_annot)) {
  tbl_out <- tbl_out %>%
    inner_join(row_annot, by = 'row_id')
}

tbl_out
```

### Column correlations

```{r col_median_pairwise_correlations}
# compute column pairwise correlation matrix
#col_cor_mat <- cor(dat, use = 'pairwise.complete')
col_cor_mat <- coop::pcor(dat, use = 'pairwise.complete')
median_col_cors <- apply(col_cor_mat, 2, median, na.rm = TRUE)
```

```{r average_column_median_pairwise_correlation, result = 'asis'}
cat(sprintf("\n- **Average column median pairwise correlation (Mean): %0.2f**:\n", mean(median_col_cors)))
cat(sprintf("\n- **Average column median pairwise correlation (Median): %0.2f**:\n", median(median_col_cors)))
```

```{r density_plot_col_correlations}
qplot(median_col_cors, geom = 'density', fill = I('green'), alpha = 0.75) +
  xlab("Median pairwise pearson correlation") +
  ggtitle("Distribution of median pairwise correlations (columns)") +
  theme_bw() +
  theme(legend.position = 'none')
```

```{r heatmap_col_correlations, fig.width = 1920/120, fig.height = 1400/120}
heatmap_dat <- col_cor_mat[col_ind, col_ind]

# drop na's resulting from zero variance columns
# mask <- apply(heatmap_dat, 2, function(x) { sum(is.na(x)) }) != nrow(heatmap_dat)
# heatmap_dat <- heatmap_dat[mask, mask]

# heatmap_args$x <- col_cor_mat[col_ind_safe, col_ind_safe]
heatmap_args$x <- col_cor_mat[col_ind, col_ind]
heatmap_args$main <- sprintf("Column correlation matrix (n = %d)", nrow(col_cor_mat))
heatmap_args$annRow <- NULL

if (!is.null(col_color)) {
  heatmap_args[["annCol"]] <- col_mdata[col_ind, ] %>%
    select(col_color) %>%
    as.data.frame()
}

do.call(aheatmap, heatmap_args)
```

**High positive correlation columns**:

Columns with the highest positive pairwise correlations with all other columns.

```{r high_pos_cor_cols, results = 'asis'}
col_cor_dat <- data.frame(column_id = colnames(dat), cor = as.numeric(median_col_cors))

tbl_out <- col_cor_dat %>%
    arrange(desc(cor)) %>%
    head(10)

if (!is.null(col_annot)) {
  tbl_out <- tbl_out %>%
    inner_join(col_annot, by = 'column_id')
}

tbl_out
```

```{r high_neg_col_cor_header, include = min(median_col_cors) < 0, eval = min(median_col_cors) < 0, results = 'asis'}
cat('\n**High negative correlation columns**:\n')
cat('\n*Columns with the strongest inverse pairwise correlations with all other columns.\n')
```

```{r high_neg_cor_cols, include = min(median_col_cors) < 0, eval = min(median_col_cors) < 0}
tbl_out <- col_cor_dat %>%
    arrange(cor) %>%
    head(10)

if (!is.null(col_annot)) {
  tbl_out <- tbl_out %>%
    inner_join(col_annot, by = 'column_id')
}

tbl_out
```

**Low correlation columns**:

Columns with the lowest median pairwise correlation with all other columns.

```{r low_cor_cols}
tbl_out <- col_cor_dat %>%
    arrange(abs(cor)) %>%
    head(10)

if (!is.null(col_annot)) {
  tbl_out <- tbl_out %>%
    inner_join(col_annot, by = 'column_id')
}

tbl_out
```

Projections
-----------

### PCA

#### Row PCA

```{r plot_pca_rows}
# column-wise pca projections
row_pca <- prcomp(dat_complete, scale = TRUE)

# % variance explained
row_pca_var <- summary(row_pca)$importance[2, ] * 100

row_pca_dat <- cbind(row = rownames(row_pca$x)[row_ind_complete],
                     as.data.frame(row_pca$x[row_ind_complete, 1:2]))

if (!is.null(row_color)) {
  for (rowname in row_color) {
    plt_dat <- cbind(row_pca_dat, row_mdata[row_ind_complete, rowname, drop = FALSE])

    print(ggplot(plt_dat, aes_string(x = 'PC1', y = 'PC2', label = 'row', color = rowname)) +
      geom_point(size = 0.5, alpha = 0.5) +
      stat_dens2d_filter(geom = "text_repel", keep.fraction = 15 / nrow(row_pca_dat)) +
      ggtitle(sprintf("PCA (Rows / %s)", rowname)) +
      xlab(sprintf("PC1 (var = %0.2f %%)", row_pca_var[1])) +
      ylab(sprintf("PC2 (var = %0.2f %%)", row_pca_var[2])) +
      theme_bw())
  }
} else {
  ggplot(row_pca_dat, aes(x = PC1, y = PC2, label = row)) +
    geom_point(size = 0.5, alpha = 0.75) +
    stat_dens2d_filter(geom = "text_repel", keep.fraction = 15 / nrow(row_pca_dat)) +
    ggtitle("PCA (Rows)") +
    xlab(sprintf("PC1 (var = %0.2f %%)", row_pca_var[1])) +
    ylab(sprintf("PC2 (var = %0.2f %%)", row_pca_var[2])) +
    theme_bw()
}
```

```{r table_pca_rows, results = 'asis'}
row_pca_summary <- as.data.frame(summary(row_pca)$importance)

kable(row_pca_summary[, 1:min(ncol(row_pca_summary), 10)], digits = 2)
```

#### Column PCA

```{r plot_pca_columns}
# column-wise pca projections
col_pca <- prcomp(t(dat_complete), scale = TRUE)

# % variance explained
col_pca_var <- summary(col_pca)$importance[2, ] * 100

col_pca_dat <- cbind(column = rownames(col_pca$x)[col_ind_complete],
                     as.data.frame(col_pca$x[col_ind_complete, 1:2]))

if (!is.null(col_color)) {
  for (colname in col_color) {
    plt_dat <- cbind(col_pca_dat, col_mdata[col_ind_complete, colname, drop = FALSE])

    print(ggplot(plt_dat, aes_string(x = 'PC1', y = 'PC2', color = colname, label = 'column')) +
      geom_point(size = 0.5, alpha = 0.75) +
      stat_dens2d_filter(geom = "text_repel", keep.fraction = 15 / nrow(col_pca_dat)) +
      ggtitle(sprintf("PCA (Columns / %s)", colname)) +
      xlab(sprintf("PC1 (var = %0.2f %%)", col_pca_var[1])) +
      ylab(sprintf("PC2 (var = %0.2f %%)", col_pca_var[2])) +
      theme_bw())
  }
} else {
  ggplot(col_pca_dat, aes(x = PC1, y = PC2, label = column)) +
    geom_point(size = 0.5, alpha = 0.75) +
    stat_dens2d_filter(geom = "text_repel", keep.fraction = 15 / nrow(col_pca_dat)) +
    ggtitle("PCA (Columns)") +
    xlab(sprintf("PC1 (var = %0.2f %%)", col_pca_var[1])) +
    ylab(sprintf("PC2 (var = %0.2f %%)", col_pca_var[2])) +
    theme_bw()
}
```

```{r table_pca_cols, results = 'asis'}
col_pca_summary <- as.data.frame(summary(col_pca)$importance)

kable(col_pca_summary[, 1:min(ncol(col_pca_summary), 10)], digits = 2)
```

### Robust PCA

#### Row Robust PCA

```{r plot_rpca_rows}
# column-wise pca projections
row_rpca <- PcaGrid(dat_complete, k = 2, scale = TRUE)

# % variance explained
row_rpca_var <- summary(row_rpca)@importance[2, ] * 100

row_rpca_dat <- cbind(row = rownames(row_rpca$scores)[row_ind_complete],
                      as.data.frame(row_rpca$scores[row_ind_complete, 1:2]))

if (!is.null(row_color)) {
  for (rowname in row_color) {
    plt_dat <- cbind(row_rpca_dat, row_mdata[row_ind_complete, rowname, drop = FALSE])

    print(ggplot(plt_dat, aes_string(x = 'PC1', y = 'PC2', label = 'row', color = rowname)) +
      geom_point(size = 0.5, alpha = 0.5) +
      stat_dens2d_filter(geom = "text_repel", keep.fraction = 15 / nrow(row_rpca_dat)) +
      ggtitle(sprintf("Robust PCA (Rows / %s)", rowname)) +
      xlab(sprintf("PC1 (var = %0.2f %%)", row_rpca_var[1])) +
      ylab(sprintf("PC2 (var = %0.2f %%)", row_rpca_var[2])) +
      theme_bw())
  }
} else {
  ggplot(row_rpca_dat, aes(x = PC1, y = PC2, label = row)) +
    geom_point(size = 0.5, alpha = 0.75) +
    stat_dens2d_filter(geom = "text_repel", keep.fraction = 15 / nrow(row_rpca_dat)) +
    ggtitle("Robust PCA (Rows)") +
    xlab(sprintf("PC1 (var = %0.2f %%)", row_rpca_var[1])) +
    ylab(sprintf("PC2 (var = %0.2f %%)", row_rpca_var[2])) +
    theme_bw()
}
```

```{r table_rpca_rows, results = 'asis'}
row_rpca_summary <- as.data.frame(summary(row_rpca)@importance)

kable(row_rpca_summary[, 1:min(ncol(row_rpca_summary), 10)], digits = 2)
```

#### Column Robust PCA

```{r plot_rpca_columns}
# column-wise pca projections
col_rpca <- PcaGrid(t(dat_complete), k = 2, scale = TRUE)

# % variance explained
col_rpca_var <- summary(col_rpca)@importance[2, ] * 100

col_rpca_dat <- cbind(column = rownames(col_rpca$scores)[col_ind_complete],
                     as.data.frame(col_rpca$scores[col_ind_complete, 1:2]))

if (!is.null(col_color)) {
  for (colname in col_color) {
    plt_dat <- cbind(col_rpca_dat, col_mdata[col_ind_complete, colname, drop = FALSE])

    print(ggplot(plt_dat, aes_string(x = 'PC1', y = 'PC2', color = colname, label = 'column')) +
      geom_point(size = 0.5, alpha = 0.75) +
      stat_dens2d_filter(geom = "text_repel", keep.fraction = 15 / nrow(col_rpca_dat)) +
      ggtitle(sprintf("Robust PCA (Columns / %s)", colname)) +
      xlab(sprintf("PC1 (var = %0.2f %%)", col_rpca_var[1])) +
      ylab(sprintf("PC2 (var = %0.2f %%)", col_rpca_var[2])) +
      theme_bw())
  }
} else {
  ggplot(col_rpca_dat, aes(x = PC1, y = PC2, label = column)) +
    geom_point(size = 0.5, alpha = 0.75) +
    stat_dens2d_filter(geom = "text_repel", keep.fraction = 15 / nrow(col_rpca_dat)) +
    ggtitle("Robust PCA (Columns)") +
    xlab(sprintf("PC1 (var = %0.2f %%)", col_rpca_var[1])) +
    ylab(sprintf("PC2 (var = %0.2f %%)", col_rpca_var[2])) +
    theme_bw()
}
```

```{r table_rpca_cols, results = 'asis'}
col_rpca_summary <- as.data.frame(summary(col_rpca)@importance)

kable(col_rpca_summary[, 1:min(ncol(col_rpca_summary), 10)], digits = 2)
```

### UMAP

#### Row UMAP

```{r plot_umap_rows}
# row-wise UMAP projections
num_neighbors <- min(500, min(nrow(dat_complete) - 1, max(5, round(nrow(dat_complete) / 10))))

# for larger dataset, use pca to reduce dimensionality prior to nn search
umap_pca <- NULL

if (nrow(dat_complete) > 100) {
  umap_pca <- 50
}

# choose distance metric
dist_metric <- 'euclidean'

if (min(median_row_cors) < 0) {
  # in the future, we can switch to "correlation"; conda version of uwot does not
  # currently include this, however..
  dist_metric <- 'cosine'
}

row_umap_dat <- as.data.frame(umap(dat_complete, n_neighbors = num_neighbors,
                                   pca = umap_pca, metric = dist_metric,
                                   scale = FALSE, n_threads = snakemake@threads))

colnames(row_umap_dat) <- paste0("UMAP", 1:2)
rownames(row_umap_dat) <- rownames(dat_complete)

row_umap_dat <- row_umap_dat[row_ind_complete, ]

row_umap_dat <- cbind(row = rownames(row_umap_dat), row_umap_dat)

if (!is.null(row_color)) {
  for (rowname in row_color) {
    plt_dat <- cbind(row_umap_dat, row_mdata[row_ind_complete, rowname, drop = FALSE])

    print(ggplot(plt_dat, aes_string(x = 'UMAP1', y = 'UMAP2', color = rowname, label = 'row')) +
      geom_point(size = 0.5, alpha = 0.75) +
      stat_dens2d_filter(geom = "text_repel", keep.fraction = 15 / nrow(row_umap_dat)) +
      ggtitle(sprintf("UMAP (Rows / %s)", rowname)) +
      xlab("UMAP1") +
      ylab("UMAP2") +
      theme_bw())
  }
} else {
  ggplot(row_umap_dat, aes(x = UMAP1, y = UMAP2, label = row)) +
    geom_point(size = 0.5, alpha = 0.75) +
    stat_dens2d_filter(geom = "text_repel", keep.fraction = 15 / nrow(row_umap_dat)) +
    ggtitle("UMAP (Rows)") +
    xlab("UMAP1") +
    ylab("UMAP2") +
    theme_bw()
}
```

#### Column UMAP

```{r plot_umap_columns}
# column-wise UMAP projections
num_neighbors <- min(500, min(ncol(dat_complete) - 1, max(5, round(ncol(dat_complete) / 10))))

# for larger dataset, use pca to reduce dimensionality prior to nn search
umap_pca <- NULL

if (ncol(dat_complete) > 100) {
  umap_pca <- 50
}

# choose distance metric
dist_metric <- 'euclidean'

if (min(median_col_cors) < 0) {
  # in the future, we can switch to "correlation"; conda version of uwot does not
  # currently include this, however..
  dist_metric <- 'cosine'
}

col_umap_dat <- as.data.frame(umap(t(dat_complete), n_neighbors = num_neighbors,
                                   metric = dist_metric, scale = FALSE, pca = umap_pca, 
                                   n_threads = snakemake@threads))

colnames(col_umap_dat) <- paste0("UMAP", 1:2)
rownames(col_umap_dat) <- colnames(dat_complete)

col_umap_dat <- col_umap_dat[col_ind_complete, ]
col_umap_dat <- cbind(column = rownames(col_umap_dat), col_umap_dat)

if (!is.null(col_color)) {
  for (colname in col_color) {
    plt_dat <- cbind(col_umap_dat, col_mdata[col_ind_complete, colname, drop = FALSE])

    print(ggplot(plt_dat, aes_string(x = 'UMAP1', y = 'UMAP2', color = colname, label = 'column')) +
      geom_point(size = 0.5, alpha = 0.75) +
      stat_dens2d_filter(geom = "text_repel", keep.fraction = 15 / nrow(col_umap_dat)) +
      ggtitle(sprintf("UMAP (Columns / %s)", colname)) +
      xlab("UMAP1") +
      ylab("UMAP2") +
      theme_bw())
  }
} else {
  ggplot(col_umap_dat, aes(x = UMAP1, y = UMAP2, label = column)) +
    geom_point(size = 0.5, alpha = 0.75) +
    stat_dens2d_filter(geom = "text_repel", keep.fraction = 15 / nrow(col_umap_dat)) +
    ggtitle("UMAP (Columns)") +
    xlab("UMAP1") +
    ylab("UMAP2") +
    theme_bw()
}
```

